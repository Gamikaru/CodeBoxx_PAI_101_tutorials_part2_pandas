{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385b3e76-e908-42d6-a646-15fa98a32821",
   "metadata": {},
   "source": [
    "# 🏆 Pandas Practice Worksheet: From Fundamentals to Advanced! 🚀\n",
    "\n",
    "Welcome to this **hands-on** Pandas challenge! This worksheet will test and deepen your skills in **data manipulation, exploration, cleaning, and analysis**. By the end, you'll be ready to tackle **real-world** datasets with confidence.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 **Step 1: Choose and Load Your Dataset**\n",
    "Pick one of the following famous datasets to work with:\n",
    "1. **Iris Dataset** 🌸 (Flower measurements)\n",
    "2. **Wine Dataset** 🍷 (Chemical composition of wines)\n",
    "3. **Boston Housing Dataset** 🏠 (Housing prices and features)\n",
    "\n",
    "Each of these datasets is available in `sklearn.datasets`. Load it into a **Pandas `DataFrame`**.\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris, load_wine, load_boston  # Boston may be deprecated in newer sklearn\n",
    "import pandas as pd\n",
    "\n",
    "# Uncomment the dataset you want to use\n",
    "# data = load_iris()\n",
    "# data = load_wine()\n",
    "# data = load_boston()  # May require `fetch_openml(\"boston\")` if not available directly\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# If there's a target, store it separately or add it as a new column\n",
    "# df['target'] = data.target\n",
    "\n",
    "# Display first 5 rows\n",
    "df.head()\n",
    "```\n",
    "\n",
    "> **Tip:** If you’re loading the **Boston** dataset via `fetch_openml`, you may need:\n",
    "> ```python\n",
    "> from sklearn.datasets import fetch_openml\n",
    "> data = fetch_openml(name='boston', version=1)\n",
    "> df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "> df['target'] = data.target\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621db9c3-dc50-4e0e-ae97-c246a6b0568b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b5822dc-5fbc-4a22-8499-f9a322256c96",
   "metadata": {},
   "source": [
    "# 🏆 Pandas Practice Worksheet: From Fundamentals to Advanced! 🚀\n",
    "\n",
    "Welcome to this **hands-on** Pandas challenge! This worksheet will test and deepen your skills in **data manipulation, exploration, cleaning, and analysis**. By the end, you'll be ready to tackle **real-world** datasets with confidence.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 **Step 1: Choose and Load Your Dataset**\n",
    "Pick one of the following famous datasets to work with:\n",
    "1. **Iris Dataset** 🌸 (Flower measurements)\n",
    "2. **Wine Dataset** 🍷 (Chemical composition of wines)\n",
    "3. **Boston Housing Dataset** 🏠 (Housing prices and features)\n",
    "\n",
    "Each of these datasets is available in `sklearn.datasets`. Load it into a **Pandas `DataFrame`**.\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris, load_wine, load_boston  # Boston may be deprecated in newer sklearn\n",
    "import pandas as pd\n",
    "\n",
    "# Uncomment the dataset you want to use\n",
    "# data = load_iris()\n",
    "# data = load_wine()\n",
    "# data = load_boston()  # May require `fetch_openml(\"boston\")` if not available directly\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# If there's a target, store it separately or add it as a new column\n",
    "# df['target'] = data.target\n",
    "\n",
    "# Display first 5 rows\n",
    "df.head()\n",
    "```\n",
    "\n",
    "> **Tip:** If you’re loading the **Boston** dataset via `fetch_openml`, you may need:\n",
    "> ```python\n",
    "> from sklearn.datasets import fetch_openml\n",
    "> data = fetch_openml(name='boston', version=1)\n",
    "> df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "> df['target'] = data.target\n",
    "> ```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧐 **Step 2: Initial Exploration**\n",
    "1. Print the **shape** of the dataset (`.shape`).\n",
    "2. Display the **column names** (`.columns`).\n",
    "3. Check the **data types** of each column (`.dtypes`).\n",
    "4. Get a **quick overview** of any **missing values** (e.g., `df.isnull().sum()`).\n",
    "5. Generate **summary statistics** of numeric columns (`.describe()`).\n",
    "\n",
    "```python\n",
    "# Your code here!\n",
    "```\n",
    "\n",
    "> **Question:** Are there any columns that are not numeric? If so, how might that affect your analysis?\n",
    "\n",
    "---\n",
    "\n",
    "## 👀 **Step 3: Data Selection & Indexing**\n",
    "1. Select only the **first 10 rows**.\n",
    "2. Select only the columns that contain **numeric values**.\n",
    "3. Extract all rows where the **first feature column** has a value **greater than its median**.\n",
    "4. Find the row with the **maximum value** in the **last numeric column**.\n",
    "5. Use **boolean indexing** or the **`.query()`** method to filter rows in a more readable way.\n",
    "\n",
    "```python\n",
    "# Your code here!\n",
    "```\n",
    "\n",
    "> **Challenge:** Practice both **label-based indexing** (`.loc`) and **integer-based indexing** (`.iloc`) to see the difference.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 **Step 4: Data Cleaning & Transformation**\n",
    "1. Convert all column names to **lowercase** (or snake_case).\n",
    "2. Rename at least one column to a more meaningful name (e.g. `petal length (cm)` -> `petal_length`).\n",
    "3. Add a new column called `\"feature_sum\"` that contains the **sum of all feature values** for each row.\n",
    "4. **Normalize** (scale between `0` and `1`) all numeric columns.\n",
    "\n",
    "```python\n",
    "# Your code here!\n",
    "```\n",
    "\n",
    "> **Tip:** For normalization, consider using:\n",
    "> ```python\n",
    "> df_norm = (df - df.min()) / (df.max() - df.min())\n",
    "> ```\n",
    "\n",
    "---\n",
    "\n",
    "## 🚰 **Step 5: Handling Missing Data & Outliers**\n",
    "1. Check again if there are **missing values**. If so, **decide** whether to drop or fill them.\n",
    "2. For numeric columns, consider detecting **outliers** (e.g., using **IQR** or **Z-scores**):\n",
    "   - Calculate the IQR (`Q3 - Q1`).\n",
    "   - Identify outliers that fall below `(Q1 - 1.5 * IQR)` or above `(Q3 + 1.5 * IQR)`.\n",
    "3. Decide how to handle outliers (remove them, cap them, or leave as is).\n",
    "\n",
    "```python\n",
    "# Your code here!\n",
    "```\n",
    "\n",
    "> **Question:** What impact do outliers have on **mean** vs **median**? Which measure is more **robust** to outliers?\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 **Step 6: Exploratory Data Analysis (EDA)**\n",
    "1. **Group** the data by the target variable (if you have one) and calculate the **mean** for each group.\n",
    "2. Create a **box plot** of one (or more) numeric columns.\n",
    "3. Generate a **histogram** of the target variable (if categorical) or of any numeric column (if the target is numeric).\n",
    "4. Use `.value_counts()` on any **categorical** columns (like `target`) to understand class distribution.\n",
    "\n",
    "```python\n",
    "# Your code here!\n",
    "```\n",
    "\n",
    "> **Challenge:** Try a **scatter plot** or **pairplot** to see the relationships between features. For a quick pairplot:\n",
    "> ```python\n",
    "> import seaborn as sns\n",
    "> sns.pairplot(df, hue='target')\n",
    "> ```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 **Step 7: Combining & Merging Data**\n",
    "1. Create a **second DataFrame** with **random values** (same number of rows) and a matching index. Merge it with your original dataset using:\n",
    "   - An **inner join**.\n",
    "   - A **left join**.\n",
    "2. Experiment with **joining** on the target column (if applicable) or on an **artificial key**.\n",
    "\n",
    "```python\n",
    "# Your code here!\n",
    "```\n",
    "\n",
    "> **Tip:** When merging, watch out for duplicates or mismatched keys that could affect your row counts.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 **Step 8: Reshaping Data (Pivot, Melt, and More)**\n",
    "1. If you have a **long** dataset, try to **pivot** it to get a **wide** format using `pd.pivot_table` or `df.pivot`.\n",
    "2. Conversely, if you have a **wide** dataset, practice using `.melt()` to make it **long** again.\n",
    "3. Create a **pivot table** that summarizes at least one numeric feature grouped by a **categorical** variable (e.g., `target`).\n",
    "\n",
    "```python\n",
    "# Your code here!\n",
    "```\n",
    "\n",
    "> **Challenge:** Experiment with **multi-level** pivot tables or apply multiple aggregate functions (like `mean`, `std`, etc.) in one pivot.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎛️ **Step 9: Advanced GroupBy & Apply**\n",
    "1. Use **`.groupby()`** to compute **multiple aggregates** (e.g., `mean`, `median`, `std`) for each group.\n",
    "2. Create a **custom function** that transforms or summarizes your data, and apply it group-wise with `.apply()`.\n",
    "3. Explore **`.agg()`** and **`.transform()`** to see how they differ from **`.apply()`**.\n",
    "\n",
    "```python\n",
    "# Your code here!\n",
    "```\n",
    "\n",
    "> **Question:** When would you prefer `.apply()` over `.agg()` or `.transform()`?\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Step 10: Final Challenge**\n",
    "1. Write a function that returns the **top 5 rows** where the sum of all numeric columns is **above the 75th percentile** of the overall dataset.\n",
    "2. **Sort** these rows in descending order based on that sum.\n",
    "3. Save your final **cleaned dataset** as a `.csv` file.\n",
    "\n",
    "```python\n",
    "# Your code here!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 **Bonus Challenges**\n",
    "1. **Correlation Heatmap:** Use Seaborn or Matplotlib to show correlations between features.\n",
    "   ```python\n",
    "   import seaborn as sns\n",
    "   import matplotlib.pyplot as plt\n",
    "\n",
    "   plt.figure(figsize=(10, 6))\n",
    "   sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "   plt.title(\"Feature Correlation Heatmap\")\n",
    "   plt.show()\n",
    "   ```\n",
    "2. **Pairplot Analysis:** Create a pairplot colored by target (if applicable) to see pairwise relationships.\n",
    "3. **Feature Engineering:** Create new features (e.g., polynomial terms, interaction terms) and see if they reveal new insights.\n",
    "4. **Time for Stats/ML:** If your dataset is suitable, try a **basic regression or classification** with `sklearn`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎉 **Well Done!**\n",
    "If you completed this worksheet, you're **well on your way** to mastering Pandas! Try applying these concepts to **real-world datasets** or integrate **machine learning** with `sklearn`.\n",
    "\n",
    "---\n",
    "### 📝 **Final Thought:** \n",
    "- Write down one topic you still find tricky in Pandas. \n",
    "- Identify **one** new function or method you want to explore further. \n",
    "- **Action Plan:** Outline **two** specific steps you’ll take to master that function.\n",
    "\n",
    "> Remember, **practice** is the key to excellence. Keep exploring, keep coding, and have fun! 🚀\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Suggested Next Steps\n",
    "- Explore real-world datasets from [Kaggle](https://www.kaggle.com/datasets).\n",
    "- Practice more advanced **data visualization** with Plotly or Seaborn.\n",
    "- Dive into **time-series** data if it interests you (e.g., stock prices, weather data).\n",
    "- Use **GitHub** or **personal projects** to showcase your newfound skills.\n",
    "\n",
    "**Good luck** on your journey to becoming a Pandas pro! Feel free to modify any tasks based on your interests or the nature of your chosen dataset. Enjoy the learning process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd15dc94-0c05-4a27-9a14-11a1d9640374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
